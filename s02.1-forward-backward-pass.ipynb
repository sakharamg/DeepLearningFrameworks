{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d206f927","cell_type":"markdown","source":"# Forward + Backward Prop\n","metadata":{}},{"id":"37ad1018","cell_type":"markdown","source":"## 0) Imports + setup","metadata":{}},{"id":"bdaf7a71","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\ntorch.manual_seed(0)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:41:26.811294Z","iopub.execute_input":"2025-12-29T07:41:26.812159Z","iopub.status.idle":"2025-12-29T07:41:26.821708Z","shell.execute_reply.started":"2025-12-29T07:41:26.812109Z","shell.execute_reply":"2025-12-29T07:41:26.820714Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":13},{"id":"e9a158df","cell_type":"markdown","source":"## 1) Build the tiny network (Sequential only)\n\n\\[\nx \\rightarrow z_1 = w_1x + b_1 \\rightarrow h_1 = \\max(0, z_1) \\rightarrow y_{pred} = w_2h_1 + b_2\n\\]\n\nWe set weights manually so numbers are predictable.","metadata":{}},{"id":"718f52ec","cell_type":"code","source":"model = nn.Sequential(\n    nn.Linear(1, 1),  # layer 0\n    nn.ReLU(),        # layer 1\n    nn.Linear(1, 1)   # layer 2\n).to(device)\n\nwith torch.no_grad():\n    model[0].weight.fill_(2.0)  # w1 = 2\n    model[0].bias.fill_(0.0)    # b1 = 0\n    model[2].weight.fill_(3.0)  # w2 = 3\n    model[2].bias.fill_(0.0)    # b2 = 0\n\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:41:28.257863Z","iopub.execute_input":"2025-12-29T07:41:28.258468Z","iopub.status.idle":"2025-12-29T07:41:28.269154Z","shell.execute_reply.started":"2025-12-29T07:41:28.258434Z","shell.execute_reply":"2025-12-29T07:41:28.267633Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=1, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":14},{"id":"1722c53f","cell_type":"markdown","source":"## 2) Single training example\n\n- `x` shape: `(1,1)`\n- `y_true` shape: `(1,1)`\n\nMSE:\n\\[\nL = (y_{pred} - y_{true})^2\n\\]","metadata":{}},{"id":"82669d47","cell_type":"code","source":"x = torch.tensor([[1.0]], device=device)\ny_true = torch.tensor([[1.0]], device=device)\n\ncriterion = nn.MSELoss(reduction=\"mean\")\nx, y_true","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:41:30.256701Z","iopub.execute_input":"2025-12-29T07:41:30.257049Z","iopub.status.idle":"2025-12-29T07:41:30.267373Z","shell.execute_reply.started":"2025-12-29T07:41:30.257019Z","shell.execute_reply":"2025-12-29T07:41:30.266060Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(tensor([[1.]]), tensor([[1.]]))"},"metadata":{}}],"execution_count":15},{"id":"37794577","cell_type":"markdown","source":"## 3) Forward pass — step by step\n\nWe compute:\n- `z1` (first linear)\n- `h1` (ReLU)\n- `y_pred` (second linear)\n- `loss` (MSE)\n\nWe also print `grad_fn` nodes:\n- `AddmmBackward...` for Linear\n- `ReluBackward...` for ReLU","metadata":{}},{"id":"3dfcccae","cell_type":"code","source":"z1 = model[0](x)\nh1 = model[1](z1)\ny_pred = model[2](h1)\nloss = criterion(y_pred, y_true)\n\nprint(\"FORWARD VALUES\")\nprint(\"x      =\", x.item())\nprint(\"z1     =\", z1.item())\nprint(\"h1     =\", h1.item())\nprint(\"y_pred =\", y_pred.item())\nprint(\"y_true =\", y_true.item())\nprint(\"loss   =\", loss.item())\n\nprint(\"\\nAUTOGRAD NODES (grad_fn)\")\nprint(\"z1.grad_fn     =\", z1.grad_fn)\nprint(\"h1.grad_fn     =\", h1.grad_fn)\nprint(\"y_pred.grad_fn =\", y_pred.grad_fn)\nprint(\"loss.grad_fn   =\", loss.grad_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:41:32.387430Z","iopub.execute_input":"2025-12-29T07:41:32.388507Z","iopub.status.idle":"2025-12-29T07:41:32.398566Z","shell.execute_reply.started":"2025-12-29T07:41:32.388460Z","shell.execute_reply":"2025-12-29T07:41:32.397545Z"}},"outputs":[{"name":"stdout","text":"FORWARD VALUES\nx      = 1.0\nz1     = 2.0\nh1     = 2.0\ny_pred = 6.0\ny_true = 1.0\nloss   = 25.0\n\nAUTOGRAD NODES (grad_fn)\nz1.grad_fn     = <AddmmBackward0 object at 0x7b701aabab60>\nh1.grad_fn     = <ReluBackward0 object at 0x7b701aabab60>\ny_pred.grad_fn = <AddmmBackward0 object at 0x7b701aabab60>\nloss.grad_fn   = <MseLossBackward0 object at 0x7b701aabab60>\n","output_type":"stream"}],"execution_count":16},{"id":"161a5723","cell_type":"markdown","source":"## 4) Backward pass — gradients on parameters\n\nAfter `loss.backward()`, gradients appear in `.grad` of **parameters**.","metadata":{}},{"id":"d44dd37d","cell_type":"code","source":"model.zero_grad()\nloss.backward()\n\nprint(\"GRADS AFTER BACKWARD\")\nprint(\"dL/dw2 =\", model[2].weight.grad.item())\nprint(\"dL/db2 =\", model[2].bias.grad.item())\nprint(\"dL/dw1 =\", model[0].weight.grad.item())\nprint(\"dL/db1 =\", model[0].bias.grad.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:41:35.715243Z","iopub.execute_input":"2025-12-29T07:41:35.715616Z","iopub.status.idle":"2025-12-29T07:41:35.723665Z","shell.execute_reply.started":"2025-12-29T07:41:35.715589Z","shell.execute_reply":"2025-12-29T07:41:35.722537Z"}},"outputs":[{"name":"stdout","text":"GRADS AFTER BACKWARD\ndL/dw2 = 20.0\ndL/db2 = 10.0\ndL/dw1 = 30.0\ndL/db1 = 30.0\n","output_type":"stream"}],"execution_count":17},{"id":"f9362e71","cell_type":"markdown","source":"## 5) ReLU gate demo: force `z1 <= 0` so gradients stop\n\nReLU derivative:\n- if `z1 > 0` → pass gradient\n- if `z1 <= 0` → block gradient (multiply by 0)","metadata":{}},{"id":"6a0fb11e","cell_type":"code","source":"with torch.no_grad():\n    model[0].weight.fill_(-2.0)\n    model[0].bias.fill_(-0.5)\n    model[2].weight.fill_(3.0)\n    model[2].bias.fill_(0.0)\n\nz1 = model[0](x)\nh1 = model[1](z1)\ny_pred = model[2](h1)\nloss = criterion(y_pred, y_true)\n\nprint(\"FORWARD VALUES (ReLU OFF case)\")\nprint(\"z1     =\", z1.item())\nprint(\"h1     =\", h1.item())\nprint(\"y_pred =\", y_pred.item())\nprint(\"loss   =\", loss.item())\n\nmodel.zero_grad()\nloss.backward()\n\nprint(\"\\nGRADS (ReLU OFF case)\")\nprint(\"dL/dw2 =\", model[2].weight.grad.item())\nprint(\"dL/db2 =\", model[2].bias.grad.item())\nprint(\"dL/dw1 =\", model[0].weight.grad.item())\nprint(\"dL/db1 =\", model[0].bias.grad.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:34:23.920222Z","iopub.execute_input":"2025-12-29T07:34:23.921217Z","iopub.status.idle":"2025-12-29T07:34:23.934848Z","shell.execute_reply.started":"2025-12-29T07:34:23.921180Z","shell.execute_reply":"2025-12-29T07:34:23.933932Z"}},"outputs":[{"name":"stdout","text":"FORWARD VALUES (ReLU OFF case)\nz1     = -2.5\nh1     = 0.0\ny_pred = 0.0\nloss   = 1.0\n\nGRADS (ReLU OFF case)\ndL/dw2 = 0.0\ndL/db2 = -2.0\ndL/dw1 = 0.0\ndL/db1 = 0.0\n","output_type":"stream"}],"execution_count":7},{"id":"904db7af-6ace-41ff-bb8b-e9dcfa696823","cell_type":"code","source":"from torch.autograd.graph import saved_tensors_hooks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:56:45.655154Z","iopub.execute_input":"2025-12-29T07:56:45.655713Z","iopub.status.idle":"2025-12-29T07:56:45.663130Z","shell.execute_reply.started":"2025-12-29T07:56:45.655668Z","shell.execute_reply":"2025-12-29T07:56:45.661825Z"}},"outputs":[],"execution_count":43},{"id":"ff3a65cd-dcc7-47d6-b08a-808661cf19c8","cell_type":"code","source":"events = []\n\ndef pack_hook(t):\n    # called when autograd SAVES a tensor during forward\n    events.append((\"SAVE in forward\", tuple(t.shape), str(t.dtype), t.item()))\n    return t\n\ndef unpack_hook(t):\n    # called when backward READS a saved tensor\n    events.append((\"LOAD in backward\", tuple(t.shape), str(t.dtype), t.item()))\n    return t\n\nx = torch.tensor([[1.0]], requires_grad=True)\ny_true = torch.tensor([[1.0]])\n\nwith saved_tensors_hooks(pack_hook, unpack_hook):\n    y_pred = model(x)\n    loss = criterion(y_pred, y_true)\n    model.zero_grad()\n    loss.backward()\n\nfor i, (tag, shape, dtype, val) in enumerate(events):\n    print(f\"{i:02d} | {tag:15s} | shape={shape} dtype={dtype} value={val}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T07:56:46.168816Z","iopub.execute_input":"2025-12-29T07:56:46.169738Z","iopub.status.idle":"2025-12-29T07:56:46.183424Z","shell.execute_reply.started":"2025-12-29T07:56:46.169693Z","shell.execute_reply":"2025-12-29T07:56:46.182153Z"}},"outputs":[{"name":"stdout","text":"00 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=1.0\n01 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=2.0\n02 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=2.0\n03 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=2.0\n04 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=3.0\n05 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=6.0\n06 | SAVE in forward | shape=(1, 1) dtype=torch.float32 value=1.0\n07 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=6.0\n08 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=1.0\n09 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=2.0\n10 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=3.0\n11 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=2.0\n12 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=1.0\n13 | LOAD in backward | shape=(1, 1) dtype=torch.float32 value=2.0\n","output_type":"stream"}],"execution_count":44},{"id":"e86d1a13-8cf8-487c-acb6-ecd1d3791528","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e3a9f811-7300-476f-8360-af05287b1a58","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}